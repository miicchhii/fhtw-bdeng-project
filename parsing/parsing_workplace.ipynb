{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FOOL",
   "id": "aa14b8c706a994f6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load your HTML string or file\n",
    "with open(\"fool.htm\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find the main article container\n",
    "article_body = soup.find(\"div\", class_=\"article-body\")\n",
    "\n",
    "# Extract all text from <p> and <h2> tags inside it\n",
    "if article_body:\n",
    "    paragraphs = article_body.find_all(['p', 'h2'])\n",
    "    article_text = \"\\n\\n\".join(tag.get_text(strip=True) for tag in paragraphs)\n",
    "    print(article_text)\n",
    "else:\n",
    "    print(\"No article-body div found.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_article_text(html_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts readable article text from a Motley Fool-style HTML file.\n",
    "\n",
    "    Args:\n",
    "        html_path (str): Path to the HTML file.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned article text with paragraphs and section headings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        article_body = soup.find(\"div\", class_=\"article-body\")\n",
    "\n",
    "        if article_body:\n",
    "            tags = article_body.find_all(['p', 'h2'])\n",
    "            text = \"\\n\\n\".join(tag.get_text(strip=True) for tag in tags)\n",
    "            return text\n",
    "        else:\n",
    "            return \"[!] No <div class='article-body'> found in the HTML.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"[!] Error reading or parsing file: {e}\"\n"
   ],
   "id": "2ed4f08b2d1bbfb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text = extract_article_text(\"fool.htm\")\n",
    "print(text)\n"
   ],
   "id": "8f5bc774643c406a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_article_text_from_json(json_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts article text from a JSON file that contains raw HTML under the 'html' key.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned article text or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        html = data.get('html')\n",
    "        if not html:\n",
    "            return \"[!] No 'html' key found in the JSON.\"\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        article_body = soup.find(\"div\", class_=\"article-body\")\n",
    "\n",
    "        if article_body:\n",
    "            tags = article_body.find_all(['p', 'h2'])\n",
    "            text = \"\\n\\n\".join(tag.get_text(strip=True) for tag in tags)\n",
    "            return text\n",
    "        else:\n",
    "            return \"[!] No <div class='article-body'> found in the HTML.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"[!] Error processing JSON file: {e}\"\n"
   ],
   "id": "2588ac59bf067ab4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "article_text = extract_article_text_from_json(\"data/www_fool_com_54277.json\")\n",
    "print(article_text)\n"
   ],
   "id": "680487f908d95c1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BENZINGA",
   "id": "947ba2e6c1b4cb32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_benzinga_article_text(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts main article text from Benzinga-style HTML, flattens for NLP.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Main content container for the article body\n",
    "    body_div = soup.find(\"div\", {\"id\": \"article-body\"})\n",
    "    if not body_div:\n",
    "        return \"\"\n",
    "\n",
    "    # Extract paragraphs and headings\n",
    "    tags = body_div.find_all([\"p\", \"h2\", \"li\"])\n",
    "    text_parts = [tag.get_text(strip=True) for tag in tags]\n",
    "\n",
    "    # Join and clean\n",
    "    raw_text = \" \".join(text_parts)\n",
    "    clean_text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "\n",
    "    return clean_text\n"
   ],
   "id": "5d893fa929593273",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"benzinga.htm\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "text = extract_benzinga_article_text(html_content)\n",
    "print(text[:5000])  # Preview first 500 chars\n"
   ],
   "id": "80aed305b5d36670",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T07:13:37.413416Z",
     "start_time": "2025-06-21T07:13:37.401612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_zacks_article_text(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts main article text from Zacks-style HTML and removes promotional ad blocks.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    body_div = soup.find(\"div\", {\"id\": \"comtext\"})\n",
    "    if not body_div:\n",
    "        return \"\"\n",
    "\n",
    "    # Extract paragraph, heading, and list elements\n",
    "    tags = body_div.find_all([\"p\", \"h2\", \"li\"])\n",
    "    text_parts = [tag.get_text(strip=True) for tag in tags]\n",
    "\n",
    "    # Combine into a single string\n",
    "    raw_text = \" \".join(text_parts)\n",
    "    clean_text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "\n",
    "    # Remove text between known ad break markers\n",
    "    ad_pattern = r'-{5,}.*?-{5,}'\n",
    "    clean_text = re.sub(ad_pattern, '', clean_text)\n",
    "\n",
    "    return clean_text.strip()\n",
    "\n",
    "\n"
   ],
   "id": "8f3ab952ddc555f1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T07:13:57.040535Z",
     "start_time": "2025-06-21T07:13:56.939105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test locally with saved file\n",
    "with open(\"zacks.htm\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "text = extract_zacks_article_text(html_content)\n",
    "print(text)  # Preview first 5000 chars"
   ],
   "id": "8cfa866138c2aa14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There’s a new sheriff in town, or at least that’s what the budget bill says.President Trump is back in the saddle, and he’s riding in with a “Big, Beautiful Bill” that aims to reshape the fiscal landscape of America. Whether you love it or loathe it, one thing’s certain: there’s money to be made.This isn’t about political ideology. This is about dollars and cents. And if you’re the kind of investor who likes to get ahead of the curve, now’s the time to pay attention.Today, I’m breaking down exactly how Trump’s latest budget proposal can translate into a market-moving opportunity. We’re going to zero in on the sectors that are poised to benefit and understand why policy creates profit.Let’s get into it.Understanding the Budget BoomTrump’s budget isn’t a “skinny bill” or some placeholder draft. It’s a fireworks show of federal spending. This is fiscal stimulus with a red hat and a bullhorn. Infrastructure, defense, border security, energy independence, you name it, there’s a line item for it.Markets are forward-looking machines, and as the bill takes shape, capital is already shifting. Institutional money doesn’t wait until the ribbon-cutting ceremony; it loads up when the ink hits the page. That’s why understanding the thematic shifts before they materialize in quarterly earnings is key to profiting.Big Government, Big GainsIt may seem counterintuitive, but historically, markets have been fond of spending. It doesn’t matter if the budget is balanced or busted; the important thing is where the money is going. And Trump’s Big, Beautiful Bill tells us that loud and clear. Follow the money for profits.Let’s take a look at the big-ticket themes in this budget that are likely to push equity valuations higher.Defense Spending ExplosionThis one is self-explanatory right now. If there’s one part of the federal budget Trump never skimps on, it’s defense. With ongoing geopolitical tensions and a hawkish stance on global military presence, the defense budget is poised to increase significantly.Think planes, tanks, missiles, cybersecurity, satellites, and advanced warfare tech. The contractors that feed the Pentagon machine are going to be very busy. Of course, Aerospace and Defense stocks immediately come to mind. But don’t let yourself get caught up in 20th-century thinking on this one. The future of warfare is all about drones.The escalation in the Middle East is very unnerving. The threat of this conflict spilling over to other nations is real.Hard Hat Capitalism: Infrastructure Gets the Green LightTrump is back to preaching “America First,” and that includes putting steel to pavement. Roads, bridges, tunnels, ports, and broadband infrastructure are all getting a facelift.Construction stocks, raw materials, engineering firms, and specialized machinery manufacturers are among the first to receive contracts and subcontracts.Look for US-based stocks in these industries to fare the best, of course. This is a clear case of \"the rich get richer,” as stocks that benefited from Trump’s spending last time around are likely to benefit again. Don’t be afraid to revisit what worked four years ago.Continued . . .The Wall, Border Tech, and SecurityYes, the wall is back. But this time, it’s more about tech than brick. Firewalls have replaced actual walls. We’re talking surveillance, drones, biometric scanners, smart fencing, and AI-powered tracking systems.Companies involved in security hardware, software, and border protection will be bidding for billion-dollar contracts. As the world evolves and shifts increasingly to the digital realm, cybersecurity becomes paramount.Energy and Mineral IndependenceEnergy policy under Trump has always been built on independence and dominance. This budget loosens the reins on domestic drilling, pipelines, and nuclear energy—all under the banner of “unleashing American energy.”Coal is politically symbolic, but the real money is in LNG, shale, and infrastructure upgrades. Energy services, fracking equipment, and even uranium players stand to benefit.It’s more than just energy this time around. The bill was introduced to Congress around the same time as several Executive Orders aimed at achieving mineral independence for the US. That means that the US does not want to rely on imports for the critical minerals it needs to manufacture critically essential devices.Tech Reindustrialization & Anti-China SentimentThis bill has echoes of Trump’s earlier “Bring Jobs Home” campaign. This means reshoring chip production, subsidizing critical industries, and boosting American-made manufacturing, particularly in strategic sectors such as semiconductors, robotics, and aerospace.Combine that with anti-China tech policies and you’ve got a recipe for selective decoupling. Expect friendly tax treatment for U.S.-based manufacturers and aggressive tariffs or bans on Chinese tech.If you’ve been following along the NVIDIA saga at all, you’ve already seen this. One day, NVIDIA can sell lower-end chips to China, and the next day, it can’t. If you’re reading between the lines, it's best to bet on US chip manufacturers that don’t deal with the Far East.Veterans and Rural Healthcare ExpansionBipartisan support for improved care for veterans and underserved rural populations means healthcare stocks, particularly those focused on logistics, telehealth, and clinic expansion, could receive a significant tailwind.Small-Cap Federal ContractorsThe big companies, such as Lockheed and Raytheon, will get the headlines. However, the real alpha is hidden in the small- to mid-cap firms that secure subcontractor work. These companies often fly under Wall Street’s radar, and their earnings are disproportionately affected by a single large contract.I’m referring to niche suppliers of military-grade connectors, battlefield software, rural broadband specialists, or regional construction companies with existing government ties. These smaller companies are the ones that could potentially surge 10x in a portfolio, versus some of the behemoths, where a billion-dollar contract doesn’t even move the needle.Bottom LineThe One Big, Beautiful Bill is making its way through Congress. There have already been some significant winners and substantial losers as a result. These themes are not going to fall by the wayside overnight. Following the money in that bill could lead to substantial gains for investors over the next three years.The Best Way to Find Zacks’ Top PicksToday, I'm pleased to offer you full, 30-day, real-time access to every stock and ETF we recommend as part of our celebratedZacks Ultimateservice.Our expert-led recommendation services are designed to highlight the most promising stocks on the market, including the hottest AI firms, insider trades (the legal kind), home run moves, stocks under $10, earnings surprise stocks, and much more.The total cost isonly $1, and there's no obligation to spend a cent more.This includes the real-time buy and sell recommendations, along with expert market insights from ALL of Zacks' private portfolio services.While future success isn't guaranteed,Zacks Ultimatemembers recently had opportunities to close gains of+220.3%,+298.3%,+627.5%, and an incredible+1,340.0%.¹Free Bonus Report:You'll also receive our Special Report,The Semiconductor Surge: A Single Stock to Watch.As demand and revenue for semiconductor stocks continue to boom, this little-known chipmaker looks to rival NVIDIA's explosive growth moving forward.Don't wait – this opportunity ends atmidnight Sunday, June 22.GainZacks UltimateAccess and Our BonusSemiconductor SurgeReport Right Now for Just $1 >>All the best,DaveDavid BartosiakStock StrategistDave Bartosiak is Zacks' resident earnings surprise expert and the manager of Zacks’s Blockchain Innovators. He selects stocks and delivers daily commentary for our Surprise Trader portfolio.¹ The results listed above are not (or may not be) representative of the performance of all selections made by Zacks Investment Research's newsletter editors and may represent the partial close of a position. Access grants you a comprehensive list of all open and closed trades.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FINAL\n",
   "id": "a466474e4c80835"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "250c141cb23c7dc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:30.079670Z",
     "start_time": "2025-06-16T18:30:30.064027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n"
   ],
   "id": "3c03d53e8577641d",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## HTML Extraction Helper\n",
    "fool"
   ],
   "id": "e631fd810367a2a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:31.480954Z",
     "start_time": "2025-06-16T18:30:31.450302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_fool_article_text(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    article_body = soup.find(\"div\", class_=\"article-body\")\n",
    "    if article_body:\n",
    "        tags = article_body.find_all(['p', 'h2'])\n",
    "        flat_text = ' '.join(tag.get_text(strip=True) for tag in tags)\n",
    "        return re.sub(r'\\s+', ' ', flat_text).strip()\n",
    "    return \"\"\n"
   ],
   "id": "e1e216b6df83264d",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "benzinga",
   "id": "545484063999d890"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:33.303663Z",
     "start_time": "2025-06-16T18:30:33.277169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_benzinga_article_text(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    article_body = soup.find(\"div\", id=\"article-body\")\n",
    "    if article_body:\n",
    "        tags = article_body.find_all(['p', 'h2', 'li'])\n",
    "        flat_text = ' '.join(tag.get_text(strip=True) for tag in tags)\n",
    "        return re.sub(r'\\s+', ' ', flat_text).strip()\n",
    "    return \"\""
   ],
   "id": "c97619db90725a76",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dynamic dispatcher\n",
   "id": "39c88985a4580e31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:34.864448Z",
     "start_time": "2025-06-16T18:30:34.837172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_article_text_by_source(url: str, html: str) -> str:\n",
    "    if \"fool.com\" in url:\n",
    "        return extract_fool_article_text(html)\n",
    "    elif \"benzinga.com\" in url:\n",
    "        return extract_benzinga_article_text(html)\n",
    "    else:\n",
    "        return \"\"\n"
   ],
   "id": "d0e1ea041517fa79",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "full file processing",
   "id": "90b54cba79fe3fc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:40.035466Z",
     "start_time": "2025-06-16T18:30:40.020446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_json_file(input_path: str) -> str:\n",
    "    try:\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        html = data.get(\"html\", \"\")\n",
    "        url = data.get(\"url\", \"\")\n",
    "        scraping_timestamp = data.get(\"timestamp\", \"\")\n",
    "\n",
    "        article_text = extract_article_text_by_source(url, html)\n",
    "        parsed_data = {\n",
    "            \"url\": url,\n",
    "            \"scrapingTimestamp\": scraping_timestamp,\n",
    "            \"parsingTimestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"articleText\": article_text\n",
    "        }\n",
    "\n",
    "        # Create the new filename\n",
    "        dirname, filename = os.path.split(input_path)\n",
    "        cleaned_filename = filename.replace(\"scrape_raw_\", \"scrape_cleaned_\")\n",
    "        output_path = os.path.join(dirname, cleaned_filename)\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(parsed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {input_path}: {e}\"\n",
    "\n"
   ],
   "id": "c888d976b3a199c5",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Batch Processing",
   "id": "a8a6ed61ee99ccf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:42.170864Z",
     "start_time": "2025-06-16T18:30:42.139216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_all_json_files(folder_path: str):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\") and not filename.endswith(\"_parsed.json\"):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            output = process_json_file(full_path)\n",
    "            print(f\"✅ Processed: {filename} → {output}\")\n"
   ],
   "id": "fba937cf1758463e",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run Function",
   "id": "b5892f4ef684d916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:30:44.656928Z",
     "start_time": "2025-06-16T18:30:43.700825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Adjust path\n",
    "process_all_json_files(\"./data\")\n"
   ],
   "id": "ddd800ca38d4d534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed: scrape_cleaned_0.json → ./data\\scrape_cleaned_0.json\n",
      "✅ Processed: scrape_cleaned_1.json → ./data\\scrape_cleaned_1.json\n",
      "✅ Processed: scrape_cleaned_10.json → ./data\\scrape_cleaned_10.json\n",
      "✅ Processed: scrape_cleaned_29585.json → ./data\\scrape_cleaned_29585.json\n",
      "✅ Processed: scrape_cleaned_29590.json → ./data\\scrape_cleaned_29590.json\n",
      "✅ Processed: scrape_cleaned_7837.json → ./data\\scrape_cleaned_7837.json\n",
      "✅ Processed: scrape_cleaned_7848.json → ./data\\scrape_cleaned_7848.json\n",
      "✅ Processed: scrape_cleaned_9623.json → ./data\\scrape_cleaned_9623.json\n",
      "✅ Processed: scrape_cleaned_9663.json → ./data\\scrape_cleaned_9663.json\n",
      "✅ Processed: scrape_cleaned_9686.json → ./data\\scrape_cleaned_9686.json\n",
      "✅ Processed: scrape_cleaned_9707.json → ./data\\scrape_cleaned_9707.json\n",
      "✅ Processed: scrape_cleaned_9742.json → ./data\\scrape_cleaned_9742.json\n",
      "✅ Processed: scrape_cleaned_9767.json → ./data\\scrape_cleaned_9767.json\n",
      "✅ Processed: scrape_cleaned_9800.json → ./data\\scrape_cleaned_9800.json\n",
      "✅ Processed: scrape_cleaned_9828.json → ./data\\scrape_cleaned_9828.json\n",
      "✅ Processed: scrape_cleaned_9858.json → ./data\\scrape_cleaned_9858.json\n",
      "✅ Processed: scrape_cleaned_9877.json → ./data\\scrape_cleaned_9877.json\n",
      "✅ Processed: scrape_cleaned_990.json → ./data\\scrape_cleaned_990.json\n",
      "✅ Processed: scrape_cleaned_9909.json → ./data\\scrape_cleaned_9909.json\n",
      "✅ Processed: scrape_cleaned_9927.json → ./data\\scrape_cleaned_9927.json\n",
      "✅ Processed: scrape_cleaned_995.json → ./data\\scrape_cleaned_995.json\n",
      "✅ Processed: scrape_cleaned_9999.json → ./data\\scrape_cleaned_9999.json\n",
      "✅ Processed: scrape_raw_0.json → ./data\\scrape_cleaned_0.json\n",
      "✅ Processed: scrape_raw_1.json → ./data\\scrape_cleaned_1.json\n",
      "✅ Processed: scrape_raw_10.json → ./data\\scrape_cleaned_10.json\n",
      "✅ Processed: scrape_raw_29585.json → ./data\\scrape_cleaned_29585.json\n",
      "✅ Processed: scrape_raw_29590.json → ./data\\scrape_cleaned_29590.json\n",
      "✅ Processed: scrape_raw_7837.json → ./data\\scrape_cleaned_7837.json\n",
      "✅ Processed: scrape_raw_7848.json → ./data\\scrape_cleaned_7848.json\n",
      "✅ Processed: scrape_raw_9623.json → ./data\\scrape_cleaned_9623.json\n",
      "✅ Processed: scrape_raw_9663.json → ./data\\scrape_cleaned_9663.json\n",
      "✅ Processed: scrape_raw_9686.json → ./data\\scrape_cleaned_9686.json\n",
      "✅ Processed: scrape_raw_9707.json → ./data\\scrape_cleaned_9707.json\n",
      "✅ Processed: scrape_raw_9742.json → ./data\\scrape_cleaned_9742.json\n",
      "✅ Processed: scrape_raw_9767.json → ./data\\scrape_cleaned_9767.json\n",
      "✅ Processed: scrape_raw_9800.json → ./data\\scrape_cleaned_9800.json\n",
      "✅ Processed: scrape_raw_9828.json → ./data\\scrape_cleaned_9828.json\n",
      "✅ Processed: scrape_raw_9858.json → ./data\\scrape_cleaned_9858.json\n",
      "✅ Processed: scrape_raw_9877.json → ./data\\scrape_cleaned_9877.json\n",
      "✅ Processed: scrape_raw_990.json → ./data\\scrape_cleaned_990.json\n",
      "✅ Processed: scrape_raw_9909.json → ./data\\scrape_cleaned_9909.json\n",
      "✅ Processed: scrape_raw_9927.json → ./data\\scrape_cleaned_9927.json\n",
      "✅ Processed: scrape_raw_995.json → ./data\\scrape_cleaned_995.json\n",
      "✅ Processed: scrape_raw_9999.json → ./data\\scrape_cleaned_9999.json\n",
      "✅ Processed: www_fool_com_54277.json → ./data\\www_fool_com_54277.json\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
