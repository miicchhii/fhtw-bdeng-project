{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbb365a-59a0-43e6-a493-dadc874bb72c",
   "metadata": {},
   "source": [
    "# Web Scraping Exercise\n",
    "\n",
    "Web Scraping allows you to gather large volumes of data from diverse and real-time online sources. This data can be crucial for enriching your datasets, filling in gaps, and providing current information that enhances the quality and relevance of your analysis. Web scraping enables you to collect data that might not be readily available through traditional APIs or databases, offering a competitive edge by incorporating unique and comprehensive insights. Moreover, it automates the data collection process, saving time and resources while ensuring a scalable approach to continuously updating and maintaining your datasets.\n",
    "\n",
    "Ethical web scraping involves respecting website terms of service, avoiding overloading servers, and ensuring that the collected data is used responsibly and in compliance with privacy laws and regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588254e6-2157-47bd-b21e-9c55888b654d",
   "metadata": {},
   "source": [
    "Use Python, ```requests```, ```BeautifulSoup``` and/or ```pandas``` to scrape web data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef6a9f-888c-4b46-839f-e6c2055a3b44",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "afe18cce-f661-44e3-966a-f6253025b02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:12.249395Z",
     "start_time": "2025-05-07T20:16:11.831804Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6df7c955-ae58-4fb4-9e77-fa945b5a2d0e",
   "metadata": {},
   "source": [
    "## Define the Target URL"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6227173-b844-4330-ab17-fc4ed20c546c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:12.255025Z",
     "start_time": "2025-05-07T20:16:12.252322Z"
    }
   },
   "source": [
    "url = \"http://finance.yahoo.com/quote/AAPL\"\n",
    "\n",
    "#here, AAPL is the ticker symbol which can be replaced with other tickers"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "e0aa53df-3c02-43b4-8810-aaac3a0685ab",
   "metadata": {},
   "source": [
    "## Send a Request to the Website\n",
    "\n",
    "Do not forget to check the response status code"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd7ee575-a612-410c-8d4b-0d201e220eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:12.452646Z",
     "start_time": "2025-05-07T20:16:12.399172Z"
    }
   },
   "source": "request = requests.get(url)",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7fc3ab17-c3a3-4886-a600-54ff193ea1f8",
   "metadata": {},
   "source": [
    "## Parse the HTML Content\n",
    "\n",
    "Use a library to access the HTMl content"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb23d1a5-ef0e-4512-b31e-a37a83a2effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:12.463339Z",
     "start_time": "2025-05-07T20:16:12.457998Z"
    }
   },
   "source": [
    "soup = BeautifulSoup(request.content, 'html.parser')\n",
    "soup.prettify()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edge: Too Many Requests\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we run into an \"Too many requests\" issue on the first try, it seems like we have to spoof the user agent to avoid bot detection.",
   "id": "c1107214586742f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:12.954220Z",
     "start_time": "2025-05-07T20:16:12.468706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "USER_AGENTS = [\n",
    "    # Windows - Chrome\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    # Windows - Firefox\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0\",\n",
    "    # macOS - Safari\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_2_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15\",\n",
    "    # macOS - Chrome\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    # Linux - Chrome\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "    # Linux - Firefox\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64; rv:119.0) Gecko/20100101 Firefox/119.0\",\n",
    "    # Edge - Windows\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0\",\n",
    "    # Android - Chrome Mobile\n",
    "    \"Mozilla/5.0 (Linux; Android 12; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36\",\n",
    "    # iPhone - Safari\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Mobile/15E148 Safari/604.1\",\n",
    "    # iPad - Safari\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1\"\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": random.choice(USER_AGENTS),\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, timeout=10)\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#soup"
   ],
   "id": "84f365edc2769e01",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c7cbb259-602c-4644-a9ac-41d8a7fe0eb3",
   "metadata": {},
   "source": [
    "## Identify the Data to be Scraped\n",
    "\n",
    "Write a couple of sentence on the data you want to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde90e0-854f-4053-8362-c885e2c5e457",
   "metadata": {},
   "source": [
    "I want to scrape the title (name of the company), which is contained in an h1 element of class \"yf-xxeib\":\n",
    "\n",
    "&lt;h1 class=\"yf-xxbei9\"&gt;Apple Inc. (AAPL)&lt;/h1&gt;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb64f4-3159-4782-9425-efbec82b7592",
   "metadata": {},
   "source": [
    "## Extract Data\n",
    "\n",
    "Find specific elements and extract text or attributes from elements (handle pagination if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "id": "594fcecdafff3b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:13.027882Z",
     "start_time": "2025-05-07T20:16:13.022998Z"
    }
   },
   "source": [
    "for h1 in soup.find_all(\"h1\"):\n",
    "    title = h1.get_text(strip=True)\n",
    "    print(title)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo Finance\n",
      "Apple Inc. (AAPL)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It seems like there is another &lt;h1> element for the page title in the same html, so we have to check for the classname as well to get the right one",
   "id": "68981478b80d138b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:13.100932Z",
     "start_time": "2025-05-07T20:16:13.096049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title = soup.find(\"h1\", class_=\"yf-xxbei9\").get_text(strip=True)\n",
    "title"
   ],
   "id": "bba4e23d1bb2d8e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Inc. (AAPL)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:16:13.173737Z",
     "start_time": "2025-05-07T20:16:13.169765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = title.rsplit(\"(\", 1)[0].strip()\n",
    "name"
   ],
   "id": "67076819-665f-43c6-9811-1218696a1b88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Inc.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looks good, now I want to scrape the names of all the companies in my dataset",
   "id": "7fcb7fdf48ab81e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:18:22.553349Z",
     "start_time": "2025-05-07T20:16:13.309311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from time import sleep\n",
    "\n",
    "TICKER_LIST = [\n",
    "    \"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"GOOG\", \"NVDA\", \"BRK-B\", \"JNJ\",\n",
    "    \"V\", \"WMT\", \"XOM\", \"JPM\", \"O\", \"PG\", \"HD\", \"PFE\", \"MA\", \"UNH\", \"BAC\",\n",
    "    \"PEP\", \"KO\", \"DIS\", \"CVX\", \"AVGO\", \"MRK\", \"LLY\", \"ABBV\", \"INTC\", \"T\",\n",
    "    \"CSCO\", \"CMCSA\", \"MCD\", \"NKE\", \"ADBE\", \"CRM\", \"COST\", \"WFC\", \"ABT\", \"TXN\",\n",
    "    \"AMGN\", \"QCOM\", \"UPS\", \"LOW\", \"IBM\", \"GE\", \"CAT\", \"DE\", \"ORCL\", \"BA\",\n",
    "    \"MDT\", \"MS\", \"GS\", \"LMT\", \"VRTX\", \"ADI\", \"FDX\", \"ZTS\", \"SBUX\", \"DHR\"\n",
    "]\n",
    "base_url = \"http://finance.yahoo.com/quote/\"\n",
    "\n",
    "\n",
    "ticker_name_map = {}\n",
    "\n",
    "for ticker in TICKER_LIST:\n",
    "    sleep(1)\n",
    "\n",
    "    url = base_url + ticker\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": random.choice(USER_AGENTS),\n",
    "    }\n",
    "\n",
    "    request = requests.get(url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "    title = soup.find(\"h1\", class_=\"yf-xxbei9\").get_text(strip=True)\n",
    "    name = title.rsplit(\"(\", 1)[0].strip()\n",
    "    print(ticker + \": \" +name)\n",
    "    ticker_name_map[ticker] = name\n"
   ],
   "id": "fd65e25c75d8d61e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: Apple Inc.\n",
      "MSFT: Microsoft Corporation\n",
      "AMZN: Amazon.com, Inc.\n",
      "TSLA: Tesla, Inc.\n",
      "GOOG: Alphabet Inc.\n",
      "NVDA: NVIDIA Corporation\n",
      "BRK-B: Berkshire Hathaway Inc.\n",
      "JNJ: Johnson & Johnson\n",
      "V: Visa Inc.\n",
      "WMT: Walmart Inc.\n",
      "XOM: Exxon Mobil Corporation\n",
      "JPM: JPMorgan Chase & Co.\n",
      "O: Realty Income Corporation\n",
      "PG: The Procter & Gamble Company\n",
      "HD: The Home Depot, Inc.\n",
      "PFE: Pfizer Inc.\n",
      "MA: Mastercard Incorporated\n",
      "UNH: UnitedHealth Group Incorporated\n",
      "BAC: Bank of America Corporation\n",
      "PEP: PepsiCo, Inc.\n",
      "KO: The Coca-Cola Company\n",
      "DIS: The Walt Disney Company\n",
      "CVX: Chevron Corporation\n",
      "AVGO: Broadcom Inc.\n",
      "MRK: Merck & Co., Inc.\n",
      "LLY: Eli Lilly and Company\n",
      "ABBV: AbbVie Inc.\n",
      "INTC: Intel Corporation\n",
      "T: AT&T Inc.\n",
      "CSCO: Cisco Systems, Inc.\n",
      "CMCSA: Comcast Corporation\n",
      "MCD: McDonald's Corporation\n",
      "NKE: NIKE, Inc.\n",
      "ADBE: Adobe Inc.\n",
      "CRM: Salesforce, Inc.\n",
      "COST: Costco Wholesale Corporation\n",
      "WFC: Wells Fargo & Company\n",
      "ABT: Abbott Laboratories\n",
      "TXN: Texas Instruments Incorporated\n",
      "AMGN: Amgen Inc.\n",
      "QCOM: QUALCOMM Incorporated\n",
      "UPS: United Parcel Service, Inc.\n",
      "LOW: Lowe's Companies, Inc.\n",
      "IBM: International Business Machines Corporation\n",
      "GE: GE Aerospace\n",
      "CAT: Caterpillar Inc.\n",
      "DE: Deere & Company\n",
      "ORCL: Oracle Corporation\n",
      "BA: The Boeing Company\n",
      "MDT: Medtronic plc\n",
      "MS: Morgan Stanley\n",
      "GS: The Goldman Sachs Group, Inc.\n",
      "LMT: Lockheed Martin Corporation\n",
      "VRTX: Vertex Pharmaceuticals Incorporated\n",
      "ADI: Analog Devices, Inc.\n",
      "FDX: FedEx Corporation\n",
      "ZTS: Zoetis Inc.\n",
      "SBUX: Starbucks Corporation\n",
      "DHR: Danaher Corporation\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "15439eda-7402-41f6-9322-2ddecf24bf91",
   "metadata": {},
   "source": [
    "## Store Data in a Structured Format\n",
    "\n",
    "Give a brief overview of the data collected (e.g. count, fields, ...)"
   ]
  },
  {
   "cell_type": "code",
   "id": "48684760-3804-4ba0-a989-bbbf89383886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:18:22.618151Z",
     "start_time": "2025-05-07T20:18:22.615016Z"
    }
   },
   "source": [
    "print(f\"Number of Tickers in starting list: {len(TICKER_LIST)}\")\n",
    "print(f\"Number of Company names: {len(ticker_name_map)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tickers in starting list: 59\n",
      "Number of Company names: 59\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The .json file looks like this (truncated):\n",
    "\n",
    "{\n",
    "\n",
    "  \"AAPL\": \"Apple Inc.\",\n",
    "\n",
    "  \"MSFT\": \"Microsoft Corporation\",\n",
    "\n",
    "  \"AMZN\": \"Amazon.com, Inc.\",\n",
    "\n",
    "  \"TSLA\": \"Tesla, Inc.\",\n",
    "\n",
    "  \"GOOG\": \"Alphabet Inc.\",\n",
    "\n",
    "  \"NVDA\": \"NVIDIA Corporation\",\n",
    "\n",
    "  \"BRK-B\": \"Berkshire Hathaway Inc.\",\n"
   ],
   "id": "bc11c0c6bf77afa"
  },
  {
   "cell_type": "markdown",
   "id": "6517c66d-3f57-4da9-b3cd-db55c85585b3",
   "metadata": {},
   "source": [
    "## Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "03309800-94f3-4529-bb22-3a44a0fb5242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:18:22.627590Z",
     "start_time": "2025-05-07T20:18:22.622054Z"
    }
   },
   "source": [
    "# Save to JSON file\n",
    "with open(\"ticker_names.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ticker_name_map, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nSaved to ticker_names.json\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to ticker_names.json\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
